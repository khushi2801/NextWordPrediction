{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a75b442",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f696439",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, LSTM, Dense, Activation, Dropout, Bidirectional\n",
    "from keras.layers.core import RepeatVector\n",
    "from keras.models import Sequential, load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "import pickle\n",
    "import heapq\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ccee4f",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05b6a1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"data.txt\", \"r\", encoding = \"utf8\")\n",
    "lines = []\n",
    "for i in file:\n",
    "    lines.append(i)\n",
    "# print (\"Line 1: \", lines[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd8fff1",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7839038",
   "metadata": {},
   "source": [
    "### Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bff9d906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Project Gutenberg's The Adventures of Sherlock Holmes, by Arthur Conan Doyle  This eBook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever.  You may copy it, give it away or re-use it under the terms of the Project Gutenberg License included with this eBook or online at www.gutenberg.net   Title: The Adventures of Sherlock Holmes  Author: Arthur Conan Doyle  Release Date: November 29, 2002 [EBook #1661] Last Updated: May 20, 2019  Language: English  Charact\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing unwanted characters\n",
    "data = \"\"\n",
    "for i in lines:\n",
    "    data = ' '. join(lines)\n",
    "data = data.replace('\\n', '').replace('\\r', '').replace('\\ufeff', '')\n",
    "data[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e07a45a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Project Gutenberg s The Adventures of Sherlock Holmes  by Arthur Conan Doyle  This eBook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever   You may copy it  give it away or re use it under the terms of the Project Gutenberg License included with this eBook or online at www gutenberg net   Title  The Adventures of Sherlock Holmes  Author  Arthur Conan Doyle  Release Date  November 29  2002  EBook  1661  Last Updated  May 20  2019  Language  English  Charact'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map punctuation to space\n",
    "translator = str.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
    "data = data.translate(translator)\n",
    "data[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ead3008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Project Gutenberg s The Adventures of Sherlock Holmes by Arthur Conan Doyle This eBook is for the use anyone anywhere at no cost and with almost restrictions whatsoever You may copy it give away or re under terms License included this online www gutenberg net Title Author Release Date November 29 2002 EBook 1661 Last Updated May 20 2019 Language English Character set encoding UTF 8 START OF THIS PROJECT GUTENBERG EBOOK THE ADVENTURES SHERLOCK HOLMES Produced an anonymous volunteer Jose Menendez '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing repeated words\n",
    "text = []\n",
    "for i in data.split():\n",
    "    if i not in text:\n",
    "        text.append(i)  \n",
    "text[:10]\n",
    "print(\"data\")\n",
    "data = ' '.join(text)\n",
    "data[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25e366c",
   "metadata": {},
   "source": [
    "### Tokenizing Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "319dd0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding unique characters in the corpus\n",
    "chars = sorted(list(set(data)))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb32e5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique characters are:  76\n"
     ]
    }
   ],
   "source": [
    "chars_size = len(chars)\n",
    "print (\"Total unique characters are: \", chars_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39123a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total input sentences:  25018\n"
     ]
    }
   ],
   "source": [
    "# Dividing text into chuncks of 39 characters\n",
    "SEQUENCE_LENGTH = 60\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(data) - SEQUENCE_LENGTH, step):\n",
    "    sentences.append(data[i:i+SEQUENCE_LENGTH])\n",
    "    next_chars.append(data[i+SEQUENCE_LENGTH])\n",
    "print ('Total input sentences: ', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b13d1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TEMP\\ipykernel_14236\\57373370.py:2: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  x = np.zeros((len(sentences), SEQUENCE_LENGTH, len(chars)), dtype=np.bool)\n",
      "C:\\Users\\TEMP\\ipykernel_14236\\57373370.py:3: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: \n",
      " [[False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " ...\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]]\n",
      "\n",
      "Labels: \n",
      " [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False  True False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False]\n"
     ]
    }
   ],
   "source": [
    "# Generating features and labels\n",
    "x = np.zeros((len(sentences), SEQUENCE_LENGTH, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for j, char in enumerate(sentence):\n",
    "        x[i, j, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "print(\"Features: \\n\", x[0])\n",
    "print(\"\\nLabels: \\n\", y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e815dc6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906ea6f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0f5f26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c853b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11058bfb",
   "metadata": {},
   "source": [
    "# Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc35a8b",
   "metadata": {},
   "source": [
    "## Building Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b19e47ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bi_lstm_model = Sequential()\n",
    "# bi_lstm_model.add(Embedding(total_chars, 100, input_length = len(total_chars)))\n",
    "# bi_lstm_model.add(Bidirectional(LSTM(150)))\n",
    "# bi_lstm_model.add(Dense(total_words, activation = 'softmax'))\n",
    "\n",
    "model = Sequential();\n",
    "model.add(LSTM(128, input_shape=(SEQUENCE_LENGTH, chars_size), kernel_regularizer='l1'))\n",
    "model.add(Dense(chars_size, activation='softmax', kernel_regularizer='l1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f7b034b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_8 (LSTM)               (None, 128)               104960    \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 76)                9804      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 114,764\n",
      "Trainable params: 114,764\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Printing model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5a19017d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "372/372 [==============================] - 37s 93ms/step - loss: 4.6282 - accuracy: 0.1120 - val_loss: 4.2333 - val_accuracy: 0.0783\n",
      "Epoch 2/50\n",
      "372/372 [==============================] - 32s 86ms/step - loss: 3.8178 - accuracy: 0.1238 - val_loss: 4.1965 - val_accuracy: 0.1263\n",
      "Epoch 3/50\n",
      "372/372 [==============================] - 32s 86ms/step - loss: 3.7567 - accuracy: 0.1240 - val_loss: 4.2033 - val_accuracy: 0.1263\n",
      "Epoch 4/50\n",
      "372/372 [==============================] - 31s 82ms/step - loss: 3.7377 - accuracy: 0.1269 - val_loss: 4.2008 - val_accuracy: 0.1263\n",
      "Epoch 5/50\n",
      "372/372 [==============================] - 32s 86ms/step - loss: 3.7340 - accuracy: 0.1263 - val_loss: 4.2217 - val_accuracy: 0.1263\n",
      "Epoch 6/50\n",
      "372/372 [==============================] - 33s 88ms/step - loss: 3.7310 - accuracy: 0.1268 - val_loss: 4.2066 - val_accuracy: 0.1263\n",
      "Epoch 7/50\n",
      "372/372 [==============================] - 32s 85ms/step - loss: 3.7303 - accuracy: 0.1268 - val_loss: 4.2119 - val_accuracy: 0.1263\n",
      "Epoch 8/50\n",
      "372/372 [==============================] - 31s 83ms/step - loss: 3.7280 - accuracy: 0.1270 - val_loss: 4.2012 - val_accuracy: 0.1263\n",
      "Epoch 9/50\n",
      "372/372 [==============================] - 31s 83ms/step - loss: 3.7116 - accuracy: 0.1270 - val_loss: 4.1957 - val_accuracy: 0.1263\n",
      "Epoch 10/50\n",
      "372/372 [==============================] - 31s 83ms/step - loss: 3.7100 - accuracy: 0.1270 - val_loss: 4.1821 - val_accuracy: 0.1263\n",
      "Epoch 11/50\n",
      "372/372 [==============================] - 31s 83ms/step - loss: 3.7095 - accuracy: 0.1270 - val_loss: 4.1906 - val_accuracy: 0.1263\n",
      "Epoch 12/50\n",
      "372/372 [==============================] - 31s 83ms/step - loss: 3.7120 - accuracy: 0.1270 - val_loss: 4.1901 - val_accuracy: 0.1263\n",
      "Epoch 13/50\n",
      "372/372 [==============================] - 32s 86ms/step - loss: 3.7093 - accuracy: 0.1270 - val_loss: 4.1935 - val_accuracy: 0.1263\n",
      "Epoch 14/50\n",
      "372/372 [==============================] - 30s 82ms/step - loss: 3.7090 - accuracy: 0.1270 - val_loss: 4.1951 - val_accuracy: 0.1263\n",
      "Epoch 15/50\n",
      "372/372 [==============================] - 34s 90ms/step - loss: 3.7095 - accuracy: 0.1270 - val_loss: 4.2045 - val_accuracy: 0.1263\n",
      "Epoch 16/50\n",
      "101/372 [=======>......................] - ETA: 24s - loss: 3.7261 - accuracy: 0.1298"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [65]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# reduce = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=3, min_lr=0.001, verbose = 1)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39moptimizer, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m----> 5\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mhistory\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1216\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1209\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1210\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1211\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1212\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1213\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1214\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1215\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1216\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1217\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1218\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:910\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    907\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    909\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 910\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    912\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    913\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:942\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    939\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    940\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    941\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 942\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    943\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3130\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3127\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   3128\u001b[0m   (graph_function,\n\u001b[0;32m   3129\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1959\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1955\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1957\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1958\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1959\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1960\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1961\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1962\u001b[0m     args,\n\u001b[0;32m   1963\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1964\u001b[0m     executing_eagerly)\n\u001b[0;32m   1965\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:598\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    597\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 598\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    604\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    605\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    606\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    607\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    610\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    611\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:58\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     57\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 58\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     61\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training model\n",
    "optimizer = Adam(lr= 0.01)\n",
    "# reduce = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=3, min_lr=0.001, verbose = 1)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "history = model.fit(x, y, validation_split=0.05, batch_size=64, epochs=50, shuffle=True).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbde2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model\n",
    "bi_lstm_model.save('bi_lstm_model.h5')\n",
    "pickle.dump(bi_lstm_history, open('bi_lstm_history.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab7b600",
   "metadata": {},
   "source": [
    "## Evaluating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab79808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "plt.plot(history['accuracy'])\n",
    "plt.plot(history['val_accuracy'])\n",
    "plt.title('Model Accuracy for Bidirectional LSTM')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc= 'upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6b22cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss\n",
    "plt.plot(history['loss'])\n",
    "plt.plot(history['val_loss'])\n",
    "plt.title('Model Loss for Bidirectional LSTM')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc= 'upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daff7fc7",
   "metadata": {},
   "source": [
    "## Making Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b3750a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the words: Stop\n"
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "    text = input(\"Enter the words: \")\n",
    "    if text == \"Stop\":\n",
    "        break\n",
    "    else:\n",
    "        token_list = tokenizer.texts_to_sequences([text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen = max_sequence_len-1, padding='pre')\n",
    "        predicted = bi_lstm_model.predict(token_list, verbose = 0)\n",
    "        classes = np.argmax(predicted, axis = 1)\n",
    "        output_word = \"\"\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == classes:\n",
    "                output_word = word\n",
    "                break\n",
    "        text += \" \" + output_word\n",
    "        print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade16138",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6e3b4b8",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4c0ecb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm_model = Sequential()\n",
    "# lstm_model.add(Embedding(total_chars, 10, input_length = 1))\n",
    "# lstm_model.add(LSTM(1000, return_sequences = True))\n",
    "# lstm_model.add(LSTM(1000))\n",
    "# lstm_model.add(Dense(1000, activation = \"relu\"))\n",
    "# lstm_model.add(Dense(total_words, activation = \"softmax\"))\n",
    "# model = Sequential();\n",
    "# model.add(LSTM(128, return_sequences=True, input_shape=(SEQUENCE_LENGTH, len(total_chars))))\n",
    "# model.add(LSTM(128, input_shape=(SEQUENCE_LENGTH, len(total_chars))))\n",
    "# model.add(Dense(len(total_chars)))\n",
    "# model.add(Activation('softmax'))\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Embedding(10000, 10, input_length=1))\n",
    "# model.add(LSTM(1000, input_shape=(SEQUENCE_LENGTH, len(chars)), return_sequences=True))\n",
    "# model.add(LSTM(1000))\n",
    "# model.add(Dense(1000, activation=\"relu\"))\n",
    "# model.add(Dense(10000, activation=\"softmax\"))\n",
    "\n",
    "model = Sequential();\n",
    "# model.add(Embedding(chars_size, 10, input_length=1))\n",
    "model.add(LSTM(128, input_shape=(SEQUENCE_LENGTH, len(chars)), return_sequences=True))\n",
    "model.add(LSTM(128, input_shape=(SEQUENCE_LENGTH, len(chars))))\n",
    "model.add(Dense(1000, activation=\"relu\"))\n",
    "model.add(Dense(chars_size, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7978c3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_9 (LSTM)               (None, 60, 128)           104960    \n",
      "                                                                 \n",
      " lstm_10 (LSTM)              (None, 128)               131584    \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1000)              129000    \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 76)                76076     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 441,620\n",
      "Trainable params: 441,620\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Printing model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b58189fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce = ReduceLROnPlateau(monitor='loss', factor = 0.2, patience = 3, min_lr = 0.0001, verbose = 1)\n",
    "logdir = 'logsnextword'\n",
    "tensorboard_Visualization = TensorBoard(log_dir = logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29661206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "186/186 [==============================] - 61s 306ms/step - loss: 3.1641 - accuracy: 0.1279 - val_loss: 3.3437 - val_accuracy: 0.1367 - lr: 0.0010\n",
      "Epoch 2/150\n",
      "186/186 [==============================] - 56s 301ms/step - loss: 2.9048 - accuracy: 0.1842 - val_loss: 3.0944 - val_accuracy: 0.1671 - lr: 0.0010\n",
      "Epoch 3/150\n",
      "186/186 [==============================] - 56s 299ms/step - loss: 2.6435 - accuracy: 0.2405 - val_loss: 2.8601 - val_accuracy: 0.2126 - lr: 0.0010\n",
      "Epoch 4/150\n",
      "186/186 [==============================] - 56s 301ms/step - loss: 2.5036 - accuracy: 0.2620 - val_loss: 2.7095 - val_accuracy: 0.2350 - lr: 0.0010\n",
      "Epoch 5/150\n",
      "186/186 [==============================] - 56s 299ms/step - loss: 2.4220 - accuracy: 0.2758 - val_loss: 2.6865 - val_accuracy: 0.2446 - lr: 0.0010\n",
      "Epoch 6/150\n",
      "186/186 [==============================] - 57s 304ms/step - loss: 2.3520 - accuracy: 0.2937 - val_loss: 2.5952 - val_accuracy: 0.2606 - lr: 0.0010\n",
      "Epoch 7/150\n",
      "186/186 [==============================] - 56s 302ms/step - loss: 2.2927 - accuracy: 0.3093 - val_loss: 2.6226 - val_accuracy: 0.2622 - lr: 0.0010\n",
      "Epoch 8/150\n",
      "186/186 [==============================] - 57s 307ms/step - loss: 2.2403 - accuracy: 0.3204 - val_loss: 2.6201 - val_accuracy: 0.2726 - lr: 0.0010\n",
      "Epoch 9/150\n",
      "186/186 [==============================] - 56s 303ms/step - loss: 2.1921 - accuracy: 0.3330 - val_loss: 2.6066 - val_accuracy: 0.2702 - lr: 0.0010\n",
      "Epoch 10/150\n",
      "186/186 [==============================] - 56s 300ms/step - loss: 2.1473 - accuracy: 0.3404 - val_loss: 2.6440 - val_accuracy: 0.2670 - lr: 0.0010\n",
      "Epoch 11/150\n",
      "186/186 [==============================] - 56s 300ms/step - loss: 2.0994 - accuracy: 0.3534 - val_loss: 2.6239 - val_accuracy: 0.2950 - lr: 0.0010\n",
      "Epoch 12/150\n",
      "186/186 [==============================] - 57s 305ms/step - loss: 2.0456 - accuracy: 0.3685 - val_loss: 2.6941 - val_accuracy: 0.2878 - lr: 0.0010\n",
      "Epoch 13/150\n",
      "186/186 [==============================] - 56s 302ms/step - loss: 1.9880 - accuracy: 0.3828 - val_loss: 2.6980 - val_accuracy: 0.2830 - lr: 0.0010\n",
      "Epoch 14/150\n",
      "186/186 [==============================] - 56s 300ms/step - loss: 1.9240 - accuracy: 0.3986 - val_loss: 2.8071 - val_accuracy: 0.2854 - lr: 0.0010\n",
      "Epoch 15/150\n",
      "186/186 [==============================] - 56s 303ms/step - loss: 1.8469 - accuracy: 0.4206 - val_loss: 2.8887 - val_accuracy: 0.2862 - lr: 0.0010\n",
      "Epoch 16/150\n",
      "186/186 [==============================] - 56s 301ms/step - loss: 1.7629 - accuracy: 0.4466 - val_loss: 3.0713 - val_accuracy: 0.2710 - lr: 0.0010\n",
      "Epoch 17/150\n",
      "186/186 [==============================] - 56s 301ms/step - loss: 1.6686 - accuracy: 0.4717 - val_loss: 3.0694 - val_accuracy: 0.2670 - lr: 0.0010\n",
      "Epoch 18/150\n",
      "186/186 [==============================] - 56s 301ms/step - loss: 1.5604 - accuracy: 0.5080 - val_loss: 3.2268 - val_accuracy: 0.2822 - lr: 0.0010\n",
      "Epoch 19/150\n",
      "186/186 [==============================] - 60s 320ms/step - loss: 1.4506 - accuracy: 0.5405 - val_loss: 3.4159 - val_accuracy: 0.2670 - lr: 0.0010\n",
      "Epoch 20/150\n",
      " 55/186 [=======>......................] - ETA: 44s - loss: 1.2703 - accuracy: 0.6028"
     ]
    }
   ],
   "source": [
    "model.compile(loss = \"categorical_crossentropy\", optimizer = Adam(lr=0.001), metrics = ['accuracy'])\n",
    "history = model.fit(x, y, validation_split = 0.05, epochs = 150, batch_size = 128, callbacks = [reduce, tensorboard_Visualization]).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5aec260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model\n",
    "lstm_model.save('lstm_model.h5')\n",
    "pickle.dump(lstm_history, open('lstm_history.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a324a58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73b28da",
   "metadata": {},
   "outputs": [],
   "source": [
    "OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4e836b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating and saving tokenizer for predict function\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([data])\n",
    "pickle.dump(tokenizer, open('tokenizer.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45bc4a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words:  8925\n"
     ]
    }
   ],
   "source": [
    "# Indexing unique words using tokenizer\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "print(\"Total number of words: \", total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b00de39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[72, 2], [72, 2, 73], [72, 2, 73, 3], [72, 2, 73, 3, 4], [72, 2, 73, 3, 4, 5]]\n",
      "Total input sequences are:  9600\n"
     ]
    }
   ],
   "source": [
    "# Converting words to numerical values\n",
    "token_list = tokenizer.texts_to_sequences([data])[0]\n",
    "\n",
    "# Creating input sequences that will be used to train model\n",
    "input_sequences = []\n",
    "step = 5\n",
    "for i in range(1, len(token_list), step):\n",
    "    for j in range(i, i+step):\n",
    "        n_gram_sequence = token_list[i-1:j+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "print(input_sequences[:5])\n",
    "print(\"Total input sequences are: \", len(input_sequences))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "707a78ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0, 72,  2])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making length of all input sequences same using padding\n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen = max_sequence_len, padding = 'pre'))\n",
    "input_sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "af7c20d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: \n",
      " [ 0  0  0  0 72]\n",
      "\n",
      "Labels: \n",
      " 2\n"
     ]
    }
   ],
   "source": [
    "# Create features and labels for all input sequences\n",
    "x_words, label_words = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "print(\"Features: \\n\", x_words[0])\n",
    "print(\"\\nLabels: \\n\", label_words[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3d95219e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: \n",
      " [0. 0. 1. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Convert labels array to array having binary values\n",
    "y_words = to_categorical(label_words, num_classes = total_words)\n",
    "print(\"Labels: \\n\", y_words[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3a9cc546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing label for input_sequences[0]\n",
    "# y[0][2] = 1 as for input_sequences[0], labels = 2\n",
    "y_words[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae7886e",
   "metadata": {},
   "outputs": [],
   "source": [
    "OLD2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "cba6a204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Characters:  97\n"
     ]
    }
   ],
   "source": [
    "# Finding unique characters in the corpus and indexing them\n",
    "chars = sorted(list(set(data)))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "print (\"Unique Characters: \", len(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "736b2ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Samples:  42038\n"
     ]
    }
   ],
   "source": [
    "# Dividing data into chuncks of 39 characters\n",
    "SEQUENCE_LENGTH = 39\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(data) - SEQUENCE_LENGTH, step):\n",
    "    sentences.append(data[i:i+SEQUENCE_LENGTH])\n",
    "    next_chars.append(data[i+SEQUENCE_LENGTH])\n",
    "print ('Training Samples: ',len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7f842c79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Project Gutenberg's The Adventures of Sherlock Holmes, by Ar\",\n",
       " \"ject Gutenberg's The Adventures of Sherlock Holmes, by Arthu\",\n",
       " \"t Gutenberg's The Adventures of Sherlock Holmes, by Arthur C\",\n",
       " \"utenberg's The Adventures of Sherlock Holmes, by Arthur Cona\",\n",
       " \"nberg's The Adventures of Sherlock Holmes, by Arthur Conan D\"]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "e08a14b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t', 'r', 'o', 'n', 'o']"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_chars[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c1309a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126173"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a300aaec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d36a1e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62062d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ccf45d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9f7c8b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4789,    1, 1020,    4,  128,   34,   45,  611, 2235, 2236])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a0e0b86d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[2][1020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c4e685ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words:  8931\n",
      "Total input sequences:  101619\n"
     ]
    }
   ],
   "source": [
    "total_words = len(tokenizer.word_index) + 1\n",
    "print(\"Total number of words: \", total_words)\n",
    "input_sequences = []\n",
    "for line in lines:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "#     print(\"token\", token_list)\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "#         print(n_gram_sequence)\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "print(\"Total input sequences: \", len(input_sequences))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
